{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d05882-d84e-42da-a267-7cb7435cd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, make_scorer, recall_score, f1_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 16, 25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd10270-e1b1-4122-8a5b-6e8553871ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_valid, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the 4 metrics: accuracy, precision, recall, and false positive rate\n",
    "    Also calculates the Macro avg. Accuracy, Precision, and Recall\n",
    "    and the f1-scores\n",
    "\n",
    "    Parameters:\n",
    "        y_valid (list): list of ACTUAL label values\n",
    "        y_pred (list): List of PREDICTED label values\n",
    "    \"\"\"\n",
    "    # Calculate Macro Avg and f1-score of both classes\n",
    "    report = classification_report(y_valid, y_pred)\n",
    "    print(report)\n",
    "    \n",
    "    # Calculate precision and recall directly\n",
    "    cm = confusion_matrix(y_valid, y_pred) \n",
    "    total = len(y_valid)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / total\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    # fnr = fn / (fn + tp)\n",
    "    return accuracy, precision, recall, fpr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4bbe55b-6bb0-416f-a435-7755416e3206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == \"cuda\":\n",
    "    print('GPU available')\n",
    "else:\n",
    "    print('GPU not available')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d681c02-02b7-4e59-8c27-b29c17208c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seed for Reproduciblity\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce268ed5-0538-4d2a-8b8f-043ac5183045",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_dev_set = \"610_ps4_training/trainingT1FD/cct_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e16200-3eea-4b06-b4d5-b87fb6b00de4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CONVERT DEV FILE INTO A DATAFRAME\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m task1_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(task1_dev_set)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# DO SOME PREPROCESSING: turn ssn from string into number\u001b[39;00m\n\u001b[1;32m      5\u001b[0m task1_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m task1_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# CONVERT DEV FILE INTO A DATAFRAME\n",
    "task1_df = pd.read_csv(task1_dev_set)\n",
    "\n",
    "# DO SOME PREPROCESSING: turn ssn from string into number\n",
    "task1_df['ssn'] = task1_df['ssn'].str.replace('-', '')\n",
    "task1_df['ssn'] = pd.to_numeric(task1_df['ssn'])\n",
    "\n",
    "print(type(task1_df))\n",
    "print(len(task1_df))\n",
    "print(task1_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356d232d-deb7-43d7-84e6-04a1697103ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything except the last element are features\n",
    "column_names = task1_df.columns\n",
    "label = column_names[-1]\n",
    "X = task1_df.drop(columns=[label])\n",
    "y = task1_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29cbc75-1ef8-4f0d-8f29-38aed07b81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each categorical column to numerical if needed\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    # Label encode each string column\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# print(X.dtypes)  # Check data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57695552-8eea-434a-a93e-b4e147e5bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit the model\n",
    "# def determine_important_features():\n",
    "#     num_of_trees = [30, 40, 50, 75, 80, 85, 90, 100, 150]\n",
    "#     for i in num_of_trees:\n",
    "#         model = RandomForestClassifier(n_estimators = i, random_state=seed)\n",
    "#         model.fit(X, y)\n",
    "        \n",
    "#         feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "#         print(feature_importances)\n",
    "#         print(\"\\n\\n\")\n",
    "\n",
    "# determine_important_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af46e8ef-ba81-454d-a936-811861d1b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "important_features = ['amt', 'trans_time', 'unix_time', 'trans_date', 'category', 'dob', 'profile', 'merch_long', 'trans_num', 'merch_lat', 'merchant', 'city_pop']\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3761da85-b7d6-4f6b-a9b0-06100d95b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the important feature columns only\n",
    "# print(X.keys())\n",
    "X_important_features = X[important_features]\n",
    "# print(X_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930955f8-17de-4704-aa5c-6a8e3ae4db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data structure from pandas to numpy \n",
    "X_numpy_arr = X_important_features.to_numpy()\n",
    "y_numpy_arr = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1854dbc1-6b90-4355-b9fd-8d3440b54226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameter grid for n_estimators\n",
    "# # num_of_trees = [i for i in range(10, 90)]\n",
    "# # num_of_trees = [10, 20, 50, 75]\n",
    "# # num_of_tress = [30, 40, 50, 75, 80, 85, 90]\n",
    "# num_of_trees = [75, 80, 85, 90]\n",
    "# param_grid = {'n_estimators': num_of_trees}\n",
    "\n",
    "# # Initialize RandomForestClassifier\n",
    "# rf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# # Set up StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# # Create a custom scoring function to maximize recall\n",
    "# scorer = make_scorer(recall_score, average='binary')\n",
    "\n",
    "# # Set up GridSearchCV with recall scoring and StratifiedKFold cross-validation\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring=scorer, cv=skf)\n",
    "\n",
    "# # Run grid search\n",
    "# grid_search.fit(X_numpy_arr, y_numpy_arr)\n",
    "\n",
    "# # Get the best model and parameters\n",
    "# best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "# best_recall = grid_search.best_score_\n",
    "\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "# print(f\"Highest recall across splits: {best_recall}\")\n",
    "# # this best_recall should match the recall below\n",
    "\n",
    "# # gridsearchCV is only finding the best number of features \n",
    "# # once you have the best number of features\n",
    "# # retrain on each train/valid split using the SAME seed \n",
    "# # to find the best train/valid split, accuracy, and macro average f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe04cb6e-e902-48c2-895c-ec967cd75a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_stratified_k_fold_RFECV(rf_model):\n",
    "    # Use stratified K-fold, k = number of splits\n",
    "    k = 10\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    models = []\n",
    "    # PERFORM Stratified K-fold training and testing\n",
    "    for train_index, valid_index in skf.split(X_numpy_arr, y_numpy_arr):\n",
    "        # train_index, valid_index = next(iter(skf.split(X_numpy_arr, y_numpy_arr)))\n",
    "        \n",
    "        # SPLIT DEV SET INTO TRAINING AND VALIDATION\n",
    "        X_train, X_valid = X_numpy_arr[train_index], X_numpy_arr[valid_index]\n",
    "        y_train, y_valid = y_numpy_arr[train_index], y_numpy_arr[valid_index]\n",
    "        \n",
    "        # Use RFECV to select optimal number of features with cross-validation\n",
    "        rfecv = RFECV(estimator=rf_model, step=5, cv=StratifiedKFold(5), scoring='recall_macro')\n",
    "        \n",
    "        # Fit RFECV to the data\n",
    "        rfecv.fit(X_train, y_train)\n",
    "        \n",
    "        # IDENTIFY the Optimal number of features\n",
    "        optimal_num_of_features = rfecv.n_features_\n",
    "        print(\"Optimal number of features: %d\" % optimal_num_of_features)\n",
    "        \n",
    "        # TRAIN your model with those features\n",
    "        X_train_optimal = X_train[:, rfecv.support_]  # Select the optimal features\n",
    "        rf_model.fit(X_train_optimal, y_train)\n",
    "        \n",
    "        # VALIDATION\n",
    "        X_valid_optimal = X_valid[:, rfecv.support_]  # Select the optimal features\n",
    "        y_pred = rf_model.predict(X_valid_optimal)\n",
    "        \n",
    "        # Compute multi-class recall\n",
    "        macro_avg_recall = recall_score(y_valid, y_pred, average='macro')  # Macro-average recall\n",
    "        print(f\"Macro-average Recall: {macro_avg_recall}\")\n",
    "        \n",
    "        # Compute accuracy and f1 score\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        macro_avg_f1_score = f1_score(y_valid, y_pred, average='macro')\n",
    "        \n",
    "        # Save metrics\n",
    "        temp_list = [train_index, valid_index, macro_avg_recall, accuracy, macro_avg_f1_score]\n",
    "        models.append(temp_list)\n",
    "    return models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf49376d-5a4f-4762-8b00-df03b5acb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9287566072511839\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9287566072511839\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9301030566526743\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9315212184015966\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9371364955193404\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9301532552958767\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9245308069433897\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9439417348626986\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9385044580079323\n",
      "Optimal number of features: 7\n",
      "Macro-average Recall: 0.9468915176136865\n"
     ]
    }
   ],
   "source": [
    "# num_of_tress = best_n_estimators\n",
    "num_of_trees = 15\n",
    "# default n_estimators, which controls the number of trees in the forest, is 100\n",
    "optimal_rf = RandomForestClassifier(random_state=seed, n_estimators = num_of_trees)\n",
    "\n",
    "# TRAIN MODEL\n",
    "models = do_stratified_k_fold_RFECV(optimal_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c467e5d5-692a-4eca-acb6-674575d2e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index with the greatest RECALL 9\n"
     ]
    }
   ],
   "source": [
    "# temp_list = [train_index, valid_index, macro_avg_recall, accuracy, macro_avg_f1_score]\n",
    "\n",
    "recalls = []\n",
    "for i, list_of_metrics in enumerate(models):\n",
    "    r = list_of_metrics[2]\n",
    "    recalls.append(r)\n",
    "    \n",
    "index_max_recall = np.argmax(recalls)\n",
    "print(\"index with the greatest RECALL\", index_max_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4302dd1-1f71-4067-b48b-2d219da95541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.9468915176136865\n",
      "accuracy: 0.9993864155251142\n",
      "my_f1_score: 0.9724310218663827\n",
      "check f1 score: 0.9683670825894657\n"
     ]
    }
   ],
   "source": [
    "# Get the best indices for training\n",
    "# temp_list = [train_index, valid_index, macro_avg_recall, accuracy, macro_avg_f1_score]\n",
    "\n",
    "# best_metrics = models[index_min_FNR]\n",
    "best_metrics = models[index_max_recall]\n",
    "train_indices = best_metrics[0]\n",
    "valid_indices = best_metrics[1]\n",
    "recall = best_metrics[2]\n",
    "accuracy = best_metrics[3]\n",
    "calculated_f1_score = best_metrics[4]\n",
    "precision = best_metrics[3]\n",
    "# fpr = best_metrics[5]\n",
    "# fnr = best_metrics[6]\n",
    "\n",
    "# print(train_indices)\n",
    "print(\"recall:\", recall)\n",
    "print(\"accuracy:\", accuracy)\n",
    "\n",
    "my_f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"my_f1_score:\", my_f1_score)\n",
    "print(\"check f1 score:\", calculated_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9bffecc-9810-4b8b-9b2f-99c03180af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['task1_important_features_random_forest_rfecv_model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain to get the model I guess\n",
    "# SPLIT DEV SET INTO TRAINING AND VALIDATION\n",
    "X_train, X_valid = X_numpy_arr[train_indices], X_numpy_arr[valid_indices]\n",
    "y_train, y_valid = y_numpy_arr[train_indices], y_numpy_arr[valid_indices]\n",
    "\n",
    "# Use RFECV to select optimal number of features with cross-validation\n",
    "rfecv = RFECV(estimator=optimal_rf, step=5, cv=StratifiedKFold(5), scoring='recall_macro')\n",
    "\n",
    "# Fit RFECV to the data\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# IDENTIFY the Optimal number of features\n",
    "optimal_num_of_features = rfecv.n_features_\n",
    "print(\"Optimal number of features: %d\" % optimal_num_of_features)\n",
    "\n",
    "# TRAIN your model with those features\n",
    "X_train_optimal = X_train[:, rfecv.support_]  # Select the optimal features\n",
    "optimal_rf.fit(X_train_optimal, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(optimal_rf, 'task1_important_features_random_forest_rfecv_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04d04bcd-ecfa-433e-8f97-568f4c3436d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rfecv.support_ to get the mask of selected features\n",
    "# print(rfecv.support_)\n",
    "# selected_feature_names = [feature for feature, selected in zip(important_features, rfecv.support_) if selected]\n",
    "# print(\"Selected features:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aedd3b8-27a3-4ee4-9466-282e71ecd282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69722\n",
      "           1       0.98      0.89      0.94       358\n",
      "\n",
      "    accuracy                           1.00     70080\n",
      "   macro avg       0.99      0.95      0.97     70080\n",
      "weighted avg       1.00      1.00      1.00     70080\n",
      "\n",
      "recall: 0.8938547486033519\n",
      "accuracy: 0.9993864155251142\n",
      "Macro-average Recall: 0.9468915176136865\n",
      "Accuracy: 0.9993864155251142\n",
      "Macro average F1 score: 0.9683670825894657\n",
      "f1_score_for_fraud: 0.9370424597364568\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "rf_loaded = joblib.load('task1_important_features_random_forest_rfecv_model.joblib')\n",
    "\n",
    "# VALIDATION\n",
    "X_valid_optimal = X_valid[:, rfecv.support_]  # Select the optimal features\n",
    "y_pred = rf_loaded.predict(X_valid_optimal)\n",
    "\n",
    "accuracy, precision, recall, fpr, fnr = calculate_metrics(y_valid, y_pred)\n",
    "print(\"recall:\", recall)\n",
    "print(\"accuracy:\", accuracy)\n",
    "\n",
    "# CALCULATE Macro-average recall\n",
    "macro_avg_recall = recall_score(y_valid, y_pred, average='macro')\n",
    "\n",
    "# CALCULATE accuracy and f1 score\n",
    "model_accuracy = accuracy_score(y_valid, y_pred)\n",
    "macro_avg_f1_score = f1_score(y_valid, y_pred, average='macro')\n",
    "f1_score_for_fraud = f1_score(y_valid, y_pred, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Macro-average Recall: {macro_avg_recall}\")\n",
    "# Macro-average Recall: 0.9468915176136865\n",
    "\n",
    "print(\"Accuracy:\", model_accuracy)\n",
    "# accuracy: 0.9468915176136865\n",
    "\n",
    "print(\"Macro average F1 score:\", macro_avg_f1_score)\n",
    "\n",
    "print(\"f1_score_for_fraud:\", f1_score_for_fraud)\n",
    "# my_f1_score: 0.9836322573014133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e49d5-c479-4f6e-b1b8-96e79bc265fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
